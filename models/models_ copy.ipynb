{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7efcf42",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d52c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94082afe",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37436d88",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d0cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac5e47",
   "metadata": {},
   "source": [
    "Sorting by year (avoids misshifting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d678255",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by='Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2ab11",
   "metadata": {},
   "source": [
    "Define target columns for model and add new column for previous year pending cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5dc9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_specific = [column for column in data.columns if 'CC' in column and column != 'CC_all']\n",
    "target_all = 'CC_all'\n",
    "for column in [col for col in data.columns if 'PC' in col or 'CC' in col]:\n",
    "    data[column + '_prev_year'] = data.groupby(['Court', 'Municipality', 'Bench'])[column].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f0d0f",
   "metadata": {},
   "source": [
    "Drop Incoming Cases and Pending Cases columns (unknown when predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d4e674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[col for col in data.columns if 'PC_all' in col or 'IC' in col or ('PC' in col and '_prev_year' not in col) or 'CC_all' in col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad95fa2",
   "metadata": {},
   "source": [
    "Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d2baf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Court', 'Municipality', 'Bench']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb8e78",
   "metadata": {},
   "source": [
    "Drop 'Informatic People' variable - only 1 entry in 2017, with value 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67a436a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Informatic People'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6d1c1",
   "metadata": {},
   "source": [
    "Drop Justice Officials - sum of 6 prior columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d92b80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Justice Officials'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66e3bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0, how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ace0f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1175e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2023 = data[data['Year'] == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f2feee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a8869",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26eda386",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data.drop(columns=target_specific), data[target_specific], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b7acc",
   "metadata": {},
   "source": [
    "Train test split for ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "720d432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ensemble = train_X.sample(frac=0.75, random_state=42)\n",
    "train_y_ensemble = train_y.loc[train_X_ensemble.index]\n",
    "validation_X_ensemble = train_X.drop(train_X_ensemble.index)\n",
    "validation_y_ensemble = train_y.loc[validation_X_ensemble.index]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_X_lr = train_X_ensemble.sample(frac=0.33, random_state=42)\n",
    "train_y_lr = train_y_ensemble.loc[train_X_lr.index]\n",
    "\n",
    "train_X_rf = train_X_ensemble.drop(train_X_lr.index).sample(frac=0.5, random_state=42)\n",
    "train_y_rf = train_y_ensemble.loc[train_X_rf.index]\n",
    "\n",
    "train_X_xgb = train_X_ensemble.drop(train_X_lr.index).drop(train_X_rf.index)\n",
    "train_y_xgb = train_y_ensemble.loc[train_X_xgb.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e520f198",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cfecf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Court\n",
      "Municipality\n",
      "Bench\n",
      "Judges\n",
      "Justice Secretary\n",
      "Law Clerck\n",
      "Auxiliar Clerck\n",
      "Administrative/Technical People\n",
      "Operational/Auxiliar People\n",
      "CC_Civil_prev_year\n",
      "CC_Criminal_prev_year\n",
      "CC_labor_prev_year\n",
      "CC_criminal_labor_prev_year\n",
      "CC_tutelar_prev_year\n",
      "CC_militar_prev_year\n",
      "PC_Civil_prev_year\n",
      "PC_Criminal_prev_year\n",
      "PC_labor_prev_year\n",
      "PC_criminal_labor_prev_year\n",
      "PC_tutelar_prev_year\n",
      "PC_militar_prev_year\n"
     ]
    }
   ],
   "source": [
    "print('Court')\n",
    "print('Municipality')\n",
    "print('Bench')\n",
    "for col in train_X.columns:\n",
    "    print(col) if 'Court' not in col and 'Municipality' not in col and 'Bench' not in col else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed25cac0",
   "metadata": {},
   "source": [
    "# First models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80181b41",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee0d6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 74590.44995759119, Mean Absolute Error: 54.07209499575911, R2 Score: 0.9299592752109356\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_X, train_y)\n",
    "\n",
    "predictions_lr = lr.predict(test_X)\n",
    "predictions_lr = predictions_lr.round(0)\n",
    "\n",
    "\n",
    "mse_lr = mean_squared_error(test_y, predictions_lr)\n",
    "mae_lr = mean_absolute_error(test_y, predictions_lr)\n",
    "r2_lr = r2_score(test_y, predictions_lr)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_lr}, Mean Absolute Error: {mae_lr}, R2 Score: {r2_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8e87ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_regression.joblib']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, 'linear_regression.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a031d19",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb5c2faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 101205.20483460561, Mean Absolute Error: 44.749787955894824, R2 Score: 0.7953032935568632\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "dt.fit(train_X, train_y)\n",
    "\n",
    "predictions_dt = dt.predict(test_X)\n",
    "predictions_dt = predictions_dt.round(0)\n",
    "\n",
    "mse_dt = mean_squared_error(test_y, predictions_dt)\n",
    "mae_dt = mean_absolute_error(test_y, predictions_dt)\n",
    "r2_dt = r2_score(test_y, predictions_dt)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_dt}, Mean Absolute Error: {mae_dt}, R2 Score: {r2_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e14486a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "248\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dt.max_features_)\n",
    "print(dt.n_features_in_)\n",
    "print(dt.n_outputs_)\n",
    "dt.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c27f4",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfbb78e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 112877.15625, Mean Absolute Error: 38.06340408325195, R2 Score: 0.9024385809898376\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "xgb.fit(train_X, train_y)\n",
    "\n",
    "predictions_xgb = xgb.predict(test_X)\n",
    "predictions_xgb = predictions_xgb.round(0)\n",
    "\n",
    "mse_xgb = mean_squared_error(test_y, predictions_xgb)\n",
    "mae_xgb = mean_absolute_error(test_y, predictions_xgb)\n",
    "r2_xgb = r2_score(test_y, predictions_xgb)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_xgb}, Mean Absolute Error: {mae_xgb}, R2 Score: {r2_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95317fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb.joblib']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb, 'xgb.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63500b9f",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ecba53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 80186.38486005088, Mean Absolute Error: 35.82251908396946, R2 Score: 0.8795833922943278\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf.fit(train_X, train_y)\n",
    "\n",
    "predictions_rf = rf.predict(test_X)\n",
    "predictions_rf = predictions_rf.round(0)\n",
    "\n",
    "mse_rf = mean_squared_error(test_y, predictions_rf)\n",
    "mae_rf = mean_absolute_error(test_y, predictions_rf)\n",
    "r2_rf = r2_score(test_y, predictions_rf)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_rf}, Mean Absolute Error: {mae_rf}, R2 Score: {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bed1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rf.n_features_in_)\n",
    "print(rf.n_outputs_)\n",
    "len(rf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1db3f242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "maxd= 0\n",
    "for t in rf.estimators_:\n",
    "    if t.tree_.max_depth > maxd:\n",
    "        maxd = t.tree_.max_depth\n",
    "print(maxd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557d9a8",
   "metadata": {},
   "source": [
    "Check correlations between the errors of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c35ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_lr = test_y.values - predictions_lr\n",
    "residual_xgb = test_y.values - predictions_xgb\n",
    "residual_rf = test_y.values - predictions_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4860ba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix for CC_Civil:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.491921       0.663481\n",
      "XGBoost                     0.491921  1.000000       0.894176\n",
      "Random Forest               0.663481  0.894176       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_Criminal:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.736867       0.810291\n",
      "XGBoost                     0.736867  1.000000       0.775679\n",
      "Random Forest               0.810291  0.775679       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_labor:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.815744       0.899546\n",
      "XGBoost                     0.815744  1.000000       0.857196\n",
      "Random Forest               0.899546  0.857196       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_criminal_labor:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.849597       0.802991\n",
      "XGBoost                     0.849597  1.000000       0.889750\n",
      "Random Forest               0.802991  0.889750       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_tutelar:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.744147       0.769962\n",
      "XGBoost                     0.744147  1.000000       0.897840\n",
      "Random Forest               0.769962  0.897840       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_militar:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.738228       0.556272\n",
      "XGBoost                     0.738228  1.000000       0.127124\n",
      "Random Forest               0.556272  0.127124       1.000000\n",
      "\n",
      "\n",
      "Average Correlations Across Targets:\n",
      "('Linear Regression', 'XGBoost'): 0.729\n",
      "('Linear Regression', 'Random Forest'): 0.750\n",
      "('XGBoost', 'Random Forest'): 0.740\n"
     ]
    }
   ],
   "source": [
    "correlation_results = {}\n",
    "\n",
    "for i, target in enumerate(target_specific):\n",
    "    # Build a DataFrame for the residuals for this target\n",
    "    df_target = pd.DataFrame({\n",
    "        'Linear Regression': residual_lr[:, i],\n",
    "        'XGBoost': residual_xgb[:, i],\n",
    "        'Random Forest': residual_rf[:, i]\n",
    "    })\n",
    "\n",
    "    correlation_results[target] = df_target.corr()\n",
    "\n",
    "for target, corr_matrix in correlation_results.items():\n",
    "    print(f\"Correlation matrix for {target}:\")\n",
    "    print(corr_matrix)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "model_pairs = [\n",
    "    ('Linear Regression', 'XGBoost'),\n",
    "    ('Linear Regression', 'Random Forest'),\n",
    "    ('XGBoost', 'Random Forest')\n",
    "]\n",
    "\n",
    "avg_correlations = {pair: [] for pair in model_pairs}\n",
    "\n",
    "for i, target in enumerate(target_specific):\n",
    "    df_target = pd.DataFrame({\n",
    "        'Linear Regression': residual_lr[:, i],\n",
    "        'XGBoost': residual_xgb[:, i],\n",
    "        'Random Forest': residual_rf[:, i]\n",
    "    })\n",
    "    corr = df_target.corr()\n",
    "    for pair in model_pairs:\n",
    "        avg_correlations[pair].append(corr.loc[pair[0], pair[1]])\n",
    "\n",
    "\n",
    "print(\"Average Correlations Across Targets:\")\n",
    "for pair, values in avg_correlations.items():\n",
    "    avg_corr = np.mean(values)\n",
    "    print(f\"{pair}: {avg_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3b060",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3dc6f6",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20070b9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Perform Grid Search with Cross-Validation\u001b[39;00m\n\u001b[0;32m      8\u001b[0m grid_search_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mgrid_search_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Get the best number of estimators\u001b[39;00m\n\u001b[0;32m     12\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m grid_search_rf\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {'n_estimators': range(10,201,10), 'max_depth': range(1, 21)}\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_rf.fit(train_X, train_y)\n",
    "\n",
    "# Get the best number of estimators\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_n_estimators = grid_search_rf.best_params_['n_estimators']\n",
    "best_max_depth = grid_search_rf.best_params_['max_depth']\n",
    "print(f\"Best number of estimators: {best_n_estimators}\")\n",
    "print(f\"Best max depth: {best_max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af0bc46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 101820.5675597646, Mean Absolute Error: 39.17148055688731, R2 Score: 0.9073725601697918\n"
     ]
    }
   ],
   "source": [
    "best_rf.predict(test_X)\n",
    "\n",
    "mse_brf = mean_squared_error(test_y, best_rf.predict(test_X))\n",
    "mae_brf = mean_absolute_error(test_y, best_rf.predict(test_X))\n",
    "r2_brf = r2_score(test_y, best_rf.predict(test_X))\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_brf}, Mean Absolute Error: {mae_brf}, R2 Score: {r2_brf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00554d09",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c05a478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    'n_estimators': range(10, 101, 5),\n",
    "    'max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_xgb.fit(train_X, train_y)\n",
    "\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "grid_search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eea690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 107589.7109375, Mean Absolute Error: 46.88821029663086, R2 Score: -0.8458577990531921\n"
     ]
    }
   ],
   "source": [
    "best_xgb.predict(test_X)\n",
    "\n",
    "mse_bxgb = mean_squared_error(test_y, best_xgb.predict(test_X))\n",
    "mae_bxgb = mean_absolute_error(test_y, best_xgb.predict(test_X))\n",
    "r2_bxgb = r2_score(test_y, best_xgb.predict(test_X))\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_bxgb}, Mean Absolute Error: {mae_bxgb}, R2 Score: {r2_bxgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61251e",
   "metadata": {},
   "source": [
    "Same takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65a0f1",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc6cc1",
   "metadata": {},
   "source": [
    "Weighted Average Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3db38ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_mse_target(weights, predictions_target, y_true_target):\n",
    "    \"\"\"\n",
    "    Compute MSE for a single target variable.\n",
    "    \"\"\"\n",
    "    # Weighted prediction for one target: dot product of weights and model predictions.\n",
    "    ensemble_pred = np.dot(weights, predictions_target)  # predictions_target shape: (n_models, n_samples)\n",
    "    mse = np.mean((y_true_target - ensemble_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "def ensemble_r2_target(weights, predictions_target, y_true_target):\n",
    "    \"\"\"\n",
    "    Compute R2 for a single target variable.\n",
    "    \"\"\"\n",
    "    # Weighted prediction for one target: dot product of weights and model predictions.\n",
    "    ensemble_pred = np.dot(weights, predictions_target)  # predictions_target shape: (n_models, n_samples)\n",
    "    return -r2_score(y_true_target, ensemble_pred)\n",
    "\n",
    "def ensemble_mae_target(weights, predictions_target, y_true_target):\n",
    "    \"\"\"\n",
    "    Compute MAE for a single target variable.\n",
    "    \"\"\"\n",
    "    # Weighted prediction for one target: dot product of weights and model predictions.\n",
    "    ensemble_pred = np.dot(weights, predictions_target)  # predictions_target shape: (n_models, n_samples)\n",
    "    mae = np.mean(np.abs(y_true_target - ensemble_pred))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d2dd8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Mean Squared Error: 198420.1257421544, Mean Absolute Error: 81.97688719253605, R2 Score: 0.8881033336990193\n",
      "Random Forest:\n",
      "Mean Squared Error: 165908.79558948262, Mean Absolute Error: 41.24300254452926, R2 Score: 0.7868392271797399\n",
      "XGBoost:\n",
      "Mean Squared Error: 172991.46875, Mean Absolute Error: 45.73176193237305, R2 Score: 0.7128705978393555\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression:')\n",
    "lrs = []\n",
    "for train_idx, val_idx in kf.split(train_X_lr):\n",
    "    X_train, X_val = train_X_lr.iloc[train_idx], train_X_lr.iloc[val_idx]\n",
    "    y_train = train_y_lr.iloc[train_idx]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)  # trains on 704 samples\n",
    "    lrs.append(model)\n",
    "\n",
    "predictions_lre = np.mean([lr.predict(validation_X_ensemble) for lr in lrs], axis=0)\n",
    "predictions_lre_rounded = predictions_lre.round(0)\n",
    "mse_lre = mean_squared_error(validation_y_ensemble, predictions_lre_rounded)\n",
    "mae_lre = mean_absolute_error(validation_y_ensemble, predictions_lre_rounded)\n",
    "r2_lre = r2_score(validation_y_ensemble, predictions_lre_rounded)\n",
    "print(f\"Mean Squared Error: {mse_lre}, Mean Absolute Error: {mae_lre}, R2 Score: {r2_lre}\")\n",
    "\n",
    "print('Random Forest:')\n",
    "rfs = []\n",
    "for train_idx, val_idx in kf.split(train_X_rf):\n",
    "    X_train, X_val = train_X_rf.iloc[train_idx], train_X_rf.iloc[val_idx]\n",
    "    y_train = train_y_rf.iloc[train_idx]\n",
    "\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)  # trains on 704 samples\n",
    "    rfs.append(model)\n",
    "\n",
    "predictions_rfe = np.mean([rf.predict(validation_X_ensemble) for rf in rfs], axis=0)\n",
    "predictions_rfe_rounded = predictions_rfe.round(0)\n",
    "mse_rfe = mean_squared_error(validation_y_ensemble, predictions_rfe_rounded)\n",
    "mae_rfe = mean_absolute_error(validation_y_ensemble, predictions_rfe_rounded)\n",
    "r2_rfe = r2_score(validation_y_ensemble, predictions_rfe_rounded)\n",
    "print(f\"Mean Squared Error: {mse_rfe}, Mean Absolute Error: {mae_rfe}, R2 Score: {r2_rfe}\")\n",
    "\n",
    "print('XGBoost:')\n",
    "xgbs = []\n",
    "for train_idx, val_idx in kf.split(train_X_xgb):\n",
    "    X_train, X_val = train_X_xgb.iloc[train_idx], train_X_xgb.iloc[val_idx]\n",
    "    y_train = train_y_xgb.iloc[train_idx]\n",
    "\n",
    "    model = XGBRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)  # trains on 704 samples\n",
    "    xgbs.append(model)\n",
    "\n",
    "predictions_xgbe = np.mean([xgb.predict(validation_X_ensemble) for xgb in xgbs], axis=0)\n",
    "predictions_xgbe_rounded = predictions_xgbe.round(0)\n",
    "mse_xgbe = mean_squared_error(validation_y_ensemble, predictions_xgbe_rounded)\n",
    "mae_xgbe = mean_absolute_error(validation_y_ensemble, predictions_xgbe_rounded)\n",
    "r2_xgbe = r2_score(validation_y_ensemble, predictions_xgbe_rounded)\n",
    "print(f\"Mean Squared Error: {mse_xgbe}, Mean Absolute Error: {mae_xgbe}, R2 Score: {r2_xgbe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e462bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.array([np.mean([lr.predict(test_X) for lr in lrs], axis=0),\n",
    "                             np.mean([xgb.predict(test_X) for xgb in xgbs], axis=0), \n",
    "                             np.mean([rf.predict(test_X) for rf in rfs], axis=0)])\n",
    "test_predictions_rounded = test_predictions.round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d36e4",
   "metadata": {},
   "source": [
    "MSE as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cca20039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights and Corresponding Models per Target:\n",
      "CC_Civil:\n",
      "  Linear Regression: 0.3659\n",
      "  XGBoost: 0.4276\n",
      "  Random Forest: 0.2065\n",
      "CC_Criminal:\n",
      "  Linear Regression: 0.5608\n",
      "  XGBoost: 0.3027\n",
      "  Random Forest: 0.1365\n",
      "CC_labor:\n",
      "  Linear Regression: 0.4654\n",
      "  XGBoost: 0.0058\n",
      "  Random Forest: 0.5288\n",
      "CC_criminal_labor:\n",
      "  Linear Regression: 0.8567\n",
      "  XGBoost: 0.0360\n",
      "  Random Forest: 0.1073\n",
      "CC_tutelar:\n",
      "  Linear Regression: 0.5048\n",
      "  XGBoost: 0.2437\n",
      "  Random Forest: 0.2514\n",
      "CC_militar:\n",
      "  Linear Regression: 1.0000\n",
      "  XGBoost: 0.0000\n",
      "  Random Forest: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "n_models = 3  # Number of models\n",
    "n_targets = 6  # Number of targets\n",
    "n_samples = validation_y_ensemble.shape[0]  # Number of samples in the test set\n",
    "\n",
    "predictions = np.array([predictions_lre, predictions_xgbe, predictions_rfe])\n",
    "y_val = validation_y_ensemble.values\n",
    "\n",
    "# Assume y_val and predictions are defined as before.\n",
    "optimal_weights_per_target = np.zeros((n_models, n_targets)) # 4 models, 6 targets\n",
    "\n",
    "\n",
    "for i in range(n_targets):  # Assuming 6 targets\n",
    "    # Extract predictions for target i: shape becomes (n_models, n_samples)\n",
    "    predictions_i = predictions[:, :, i]\n",
    "    y_true_i = y_val[:, i]\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1)] * n_models\n",
    "    initial_weights = np.full(n_models, 1.0 / n_models)\n",
    "    \n",
    "    result = minimize(ensemble_mse_target, initial_weights, args=(predictions_i, y_true_i),\n",
    "                      bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    optimal_weights_per_target[:, i] = result.x\n",
    "\n",
    "model_names = ['Linear Regression', 'XGBoost', 'Random Forest']\n",
    "print(\"Optimal Weights and Corresponding Models per Target:\")\n",
    "for i, target in enumerate(target_specific):\n",
    "    print(f\"{target}:\")\n",
    "    for weight, model in zip(optimal_weights_per_target[:, i], model_names):\n",
    "        print(f\"  {model}: {weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fd1a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ensemble predictions for each target using the corresponding weights\n",
    "n_test_samples = test_predictions.shape[1]  # Number of samples in the test set\n",
    "ensemble_pred_separate = np.zeros((n_test_samples, n_targets))\n",
    "for i in range(n_targets):\n",
    "    ensemble_pred_separate[:, i] = np.dot(optimal_weights_per_target[:, i], test_predictions[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b610348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 87949.09783989836, Mean Absolute Error: 54.04997882253283, R2 Score: 0.9045132708098724\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred_separate = ensemble_pred_separate.round(0)\n",
    "ensemble_mse = mean_squared_error(test_y, ensemble_pred_separate)\n",
    "ensemble_mae = mean_absolute_error(test_y, ensemble_pred_separate)\n",
    "ensemble_r2 = r2_score(test_y, ensemble_pred_separate)\n",
    "\n",
    "print(f\"Mean Squared Error: {ensemble_mse}, Mean Absolute Error: {ensemble_mae}, R2 Score: {ensemble_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e8057",
   "metadata": {},
   "source": [
    "R^2 as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58d01a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights and Corresponding Models per Target:\n",
      "CC_Civil:\n",
      "  Linear Regression: 0.3663\n",
      "  XGBoost: 0.4280\n",
      "  Random Forest: 0.2057\n",
      "CC_Criminal:\n",
      "  Linear Regression: 0.5608\n",
      "  XGBoost: 0.3027\n",
      "  Random Forest: 0.1365\n",
      "CC_labor:\n",
      "  Linear Regression: 0.4654\n",
      "  XGBoost: 0.0058\n",
      "  Random Forest: 0.5288\n",
      "CC_criminal_labor:\n",
      "  Linear Regression: 0.8571\n",
      "  XGBoost: 0.0355\n",
      "  Random Forest: 0.1074\n",
      "CC_tutelar:\n",
      "  Linear Regression: 0.5064\n",
      "  XGBoost: 0.2439\n",
      "  Random Forest: 0.2497\n",
      "CC_militar:\n",
      "  Linear Regression: 1.0000\n",
      "  XGBoost: 0.0000\n",
      "  Random Forest: 0.0000\n"
     ]
    }
   ],
   "source": [
    "n_models = 3  # Number of models\n",
    "n_targets = 6  # Number of targets\n",
    "n_samples = validation_y_ensemble.shape[0]  # Number of samples in the validation set\n",
    "\n",
    "predictions = np.array([predictions_lre, predictions_xgbe, predictions_rfe])\n",
    "y_val = validation_y_ensemble.values\n",
    "\n",
    "# Assume y_val and predictions are defined as before.\n",
    "optimal_weights_per_target_r2 = np.zeros((n_models, n_targets)) # 3 models, 6 targets\n",
    "\n",
    "\n",
    "for i in range(n_targets):  # Assuming 6 targets\n",
    "    # Extract predictions for target i: shape becomes (n_models, n_samples)\n",
    "    predictions_i = predictions[:, :, i]\n",
    "    y_true_i = y_val[:, i]\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1)] * n_models\n",
    "    initial_weights = np.full(n_models, 1.0 / n_models)\n",
    "    \n",
    "    result = minimize(ensemble_r2_target, initial_weights, args=(predictions_i, y_true_i),\n",
    "                      bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    optimal_weights_per_target_r2[:, i] = result.x\n",
    "\n",
    "model_names = ['Linear Regression', 'XGBoost', 'Random Forest']\n",
    "print(\"Optimal Weights and Corresponding Models per Target:\")\n",
    "for i, target in enumerate(target_specific):\n",
    "    print(f\"{target}:\")\n",
    "    for weight, model in zip(optimal_weights_per_target_r2[:, i], model_names):\n",
    "        print(f\"  {model}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e685b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ensemble predictions for each target using the corresponding weights\n",
    "n_test_samples = test_predictions.shape[1]  # Number of samples in the test set\n",
    "ensemble_pred_separate_r2 = np.zeros((n_test_samples, n_targets))\n",
    "for i in range(n_targets):\n",
    "    ensemble_pred_separate_r2[:, i] = np.dot(optimal_weights_per_target_r2[:, i], test_predictions[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1088ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 85549.26950805767, Mean Absolute Error: 48.944232400339274, R2 Score: 0.8954370560710793\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred_separate_r2 = ensemble_pred_separate_r2.round(0)\n",
    "ensemble_mse = mean_squared_error(test_y, ensemble_pred_separate_r2)\n",
    "ensemble_mae = mean_absolute_error(test_y, ensemble_pred_separate_r2)\n",
    "ensemble_r2 = r2_score(test_y, ensemble_pred_separate_r2)\n",
    "\n",
    "print(f\"Mean Squared Error: {ensemble_mse}, Mean Absolute Error: {ensemble_mae}, R2 Score: {ensemble_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929a23b",
   "metadata": {},
   "source": [
    "MAE as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7924a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights and Corresponding Models per Target:\n",
      "CC_Civil:\n",
      "  Linear Regression: 0.0111\n",
      "  XGBoost: 0.2143\n",
      "  Random Forest: 0.7746\n",
      "CC_Criminal:\n",
      "  Linear Regression: 0.0989\n",
      "  XGBoost: 0.5991\n",
      "  Random Forest: 0.3019\n",
      "CC_labor:\n",
      "  Linear Regression: 0.0000\n",
      "  XGBoost: 0.0000\n",
      "  Random Forest: 1.0000\n",
      "CC_criminal_labor:\n",
      "  Linear Regression: 0.0000\n",
      "  XGBoost: 0.6529\n",
      "  Random Forest: 0.3471\n",
      "CC_tutelar:\n",
      "  Linear Regression: 0.0031\n",
      "  XGBoost: 0.7822\n",
      "  Random Forest: 0.2147\n",
      "CC_militar:\n",
      "  Linear Regression: 1.0000\n",
      "  XGBoost: 0.0000\n",
      "  Random Forest: 0.0000\n"
     ]
    }
   ],
   "source": [
    "n_models = 3  # Number of models\n",
    "n_targets = 6  # Number of targets\n",
    "n_samples = validation_y_ensemble.shape[0]  # Number of samples in the validation set\n",
    "\n",
    "predictions = np.array([predictions_lre, predictions_xgbe, predictions_rfe])\n",
    "y_val = validation_y_ensemble.values\n",
    "\n",
    "# Assume y_val and predictions are defined as before.\n",
    "optimal_weights_per_target_mae = np.zeros((n_models, n_targets)) # 3 models, 6 targets\n",
    "\n",
    "\n",
    "for i in range(n_targets):  # Assuming 6 targets\n",
    "    # Extract predictions for target i: shape becomes (n_models, n_samples)\n",
    "    predictions_i = predictions[:, :, i]\n",
    "    y_true_i = y_val[:, i]\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1)] * n_models\n",
    "    initial_weights = np.full(n_models, 1.0 / n_models)\n",
    "    \n",
    "    result = minimize(ensemble_mae_target, initial_weights, args=(predictions_i, y_true_i),\n",
    "                      bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    optimal_weights_per_target_mae[:, i] = result.x\n",
    "\n",
    "model_names = ['Linear Regression', 'XGBoost', 'Random Forest']\n",
    "print(\"Optimal Weights and Corresponding Models per Target:\")\n",
    "for i, target in enumerate(target_specific):\n",
    "    print(f\"{target}:\")\n",
    "    for weight, model in zip(optimal_weights_per_target_mae[:, i], model_names):\n",
    "        print(f\"  {model}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d7c3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ensemble predictions for each target using the corresponding weights\n",
    "n_test_samples = test_predictions.shape[1]  # Number of samples in the test set\n",
    "ensemble_pred_separate_mae = np.zeros((n_test_samples, n_targets))\n",
    "for i in range(n_targets):\n",
    "    ensemble_pred_separate_mae[:, i] = np.dot(optimal_weights_per_target_mae[:, i], test_predictions[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ae92b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 156108.75254452927, Mean Absolute Error: 40.25424088210348, R2 Score: 0.8576586121294735\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred_separate_mae = ensemble_pred_separate_mae.round(0)\n",
    "ensemble_mse = mean_squared_error(test_y, ensemble_pred_separate_mae)\n",
    "ensemble_mae = mean_absolute_error(test_y, ensemble_pred_separate_mae)\n",
    "ensemble_r2 = r2_score(test_y, ensemble_pred_separate_mae)\n",
    "\n",
    "print(f\"Mean Squared Error: {ensemble_mse}, Mean Absolute Error: {ensemble_mae}, R2 Score: {ensemble_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e96929",
   "metadata": {},
   "source": [
    "Meta-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "712119f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X = np.hstack([predictions_lre, predictions_xgbe, predictions_rfe])\n",
    "\n",
    "meta_models = []\n",
    "for i in range(6):\n",
    "    y_val_i = y_val[:, i]\n",
    "    meta_model = Ridge()\n",
    "    meta_model.fit(meta_X, y_val_i)\n",
    "    meta_models.append(meta_model)\n",
    "\n",
    "# To predict on the test set:\n",
    "meta_X_test = np.hstack([np.mean([lr.predict(test_X) for lr in lrs], axis=0),\n",
    "                             np.mean([xgb.predict(test_X) for xgb in xgbs], axis=0), \n",
    "                             np.mean([rf.predict(test_X) for rf in rfs], axis=0)]\n",
    "                             )\n",
    "\n",
    "y_pred_meta_ensemble = np.column_stack([\n",
    "    meta_model.predict(meta_X_test) for meta_model in meta_models\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c49b2163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 91558.73700924998, Mean Absolute Error: 55.617985590518686, R2 Score: 0.849659525528371\n"
     ]
    }
   ],
   "source": [
    "meta_mse = mean_squared_error(test_y, y_pred_meta_ensemble)\n",
    "meta_mae = mean_absolute_error(test_y, y_pred_meta_ensemble)\n",
    "meta_r2 = r2_score(test_y, y_pred_meta_ensemble)\n",
    "\n",
    "print(f\"Mean Squared Error: {meta_mse}, Mean Absolute Error: {meta_mae}, R2 Score: {meta_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ee3d135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 116259.46293943243, Mean Absolute Error: 39.79500211774671, R2 Score: 0.9051820007427479\n",
      "Mean Squared Error: 103286.13002964847, Mean Absolute Error: 38.64464210080474, R2 Score: 0.9106146356425548\n",
      "Mean Squared Error: 112395.8958068615, Mean Absolute Error: 39.664548919949176, R2 Score: 0.9097691849497639\n",
      "Mean Squared Error: 114282.16539601861, Mean Absolute Error: 39.40724269377383, R2 Score: 0.9069180521948127\n",
      "Mean Squared Error: 105342.02117746715, Mean Absolute Error: 38.56077933079204, R2 Score: 0.9101732744556772\n",
      "Mean Squared Error: 106317.28759000421, Mean Absolute Error: 39.302414231257934, R2 Score: 0.9036262974177296\n",
      "Mean Squared Error: 100831.59085133417, Mean Absolute Error: 38.49047013977129, R2 Score: 0.9070415002184289\n",
      "Mean Squared Error: 104960.95235069886, Mean Absolute Error: 38.71812791190174, R2 Score: 0.9073506505111171\n",
      "Mean Squared Error: 109341.61562897079, Mean Absolute Error: 38.71685726387125, R2 Score: 0.9065626985094976\n",
      "Mean Squared Error: 102795.98623464633, Mean Absolute Error: 38.592757306226176, R2 Score: 0.9099199424504757\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "\n",
    "    rfr = RandomForestRegressor()\n",
    "    rfr.fit(train_X, train_y)\n",
    "    predictions_rfr = rfr.predict(test_X)\n",
    "    predictions_rfr = predictions_rfr.round(0)\n",
    "\n",
    "    mse_rfr = mean_squared_error(test_y, predictions_rfr)\n",
    "    mae_rfr = mean_absolute_error(test_y, predictions_rfr)\n",
    "    r2_rfr = r2_score(test_y, predictions_rfr)\n",
    "    print(f\"Mean Squared Error: {mse_rfr}, Mean Absolute Error: {mae_rfr}, R2 Score: {r2_rfr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72485f2d",
   "metadata": {},
   "source": [
    "# More Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb335053",
   "metadata": {},
   "source": [
    "Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "543f2f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 73380.14609838846, Mean Absolute Error: 50.528201865988116, R2 Score: 0.9322181909701354\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=8)\n",
    "ridge.fit(train_X, train_y)\n",
    "\n",
    "predictions_ridge = ridge.predict(test_X)\n",
    "predictions_ridge = predictions_ridge.round(0)\n",
    "\n",
    "\n",
    "mse_ridge = mean_squared_error(test_y, predictions_ridge)\n",
    "mae_ridge = mean_absolute_error(test_y, predictions_ridge)\n",
    "r2_ridge = r2_score(test_y, predictions_ridge)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_ridge}, Mean Absolute Error: {mae_ridge}, R2 Score: {r2_ridge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "409f5434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ridge.joblib']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ridge, 'ridge.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be2e36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ridge.coef_, columns=train_X.columns).to_csv(\"ridge_coefs.csv\", index=False)\n",
    "pd.Series(ridge.intercept_).to_csv(\"ridge_intercepts.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60f9f6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.39000000e+02, -2.46700546e+02,  1.21828996e+01, ...,\n",
       "         1.81429945e+02, -8.24160618e+01,  1.83553667e+02],\n",
       "       [-3.86849419e+00,  1.66277722e-01,  2.55719266e+00, ...,\n",
       "        -1.25373922e+01,  2.63867711e+01,  8.18934644e+01],\n",
       "       [-2.85420270e-01,  1.31426447e+01, -1.50482171e+00, ...,\n",
       "         1.44971568e+00,  2.23058544e+00,  3.75510078e+00],\n",
       "       [ 1.87330938e-01, -7.29540189e-01, -8.48531890e-02, ...,\n",
       "        -9.86956239e-01, -1.11177661e+00,  5.89731450e-01],\n",
       "       [ 4.63146699e-01, -2.67706791e-02,  1.17250350e+00, ...,\n",
       "        -1.27717462e+01, -1.36651894e+01, -2.63664207e+00],\n",
       "       [ 3.09421589e-02,  1.45514777e-02,  4.92650419e-03, ...,\n",
       "        -3.67662728e-02,  4.18753837e-02, -5.00430271e-02]],\n",
       "      shape=(6, 248))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03b638ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.56524355e+02,  9.22888930e+00,  3.07393969e+00,  6.95010588e-01,\n",
       "        5.55776228e+00, -2.74380571e-02])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594e4e4",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "953bdeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 72029.77353689568, Mean Absolute Error: 48.008057675996604, R2 Score: 0.9120933094787619\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(train_X, train_y)\n",
    "\n",
    "predictions_lasso = lasso.predict(test_X)\n",
    "predictions_lasso = predictions_lasso.round(0)\n",
    "\n",
    "mse_lasso = mean_squared_error(test_y, predictions_lasso)\n",
    "mae_lasso = mean_absolute_error(test_y, predictions_lasso)\n",
    "r2_lasso = r2_score(test_y, predictions_lasso)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_lasso}, Mean Absolute Error: {mae_lasso}, R2 Score: {r2_lasso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d64b6",
   "metadata": {},
   "source": [
    "Elastic Net (mix of Ridge and Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eafb544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 81382.8159457167, Mean Absolute Error: 46.14249363867685, R2 Score: 0.9122718619047429\n"
     ]
    }
   ],
   "source": [
    "en = ElasticNet()\n",
    "en.fit(train_X, train_y)\n",
    "\n",
    "predictions_en = en.predict(test_X)\n",
    "predictions_en = predictions_en.round(0)\n",
    "\n",
    "mse_en = mean_squared_error(test_y, predictions_en)\n",
    "mae_en = mean_absolute_error(test_y, predictions_en)\n",
    "r2_en = r2_score(test_y, predictions_en)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_en}, Mean Absolute Error: {mae_en}, R2 Score: {r2_en}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb195d",
   "metadata": {},
   "source": [
    "Ridge alpha optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35c25a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 10.17\n",
      "Mean Squared Error: 73358.20038167939, Mean Absolute Error: 49.98409669211196, R2 Score: 0.9324519894076184\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for alpha\n",
    "param_grid_ridge = {'alpha': np.arange(0.01,15,0.01)}\n",
    "\n",
    "# Initialize the Ridge Regressor\n",
    "ridge = Ridge()\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search_ridge = GridSearchCV(estimator=ridge, param_grid=param_grid_ridge, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_ridge.fit(train_X, train_y)\n",
    "\n",
    "# Get the best alpha value\n",
    "best_ridge = grid_search_ridge.best_estimator_\n",
    "best_alpha = grid_search_ridge.best_params_['alpha']\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "predictions_best_ridge = best_ridge.predict(test_X)\n",
    "predictions_best_ridge = predictions_best_ridge.round(0)\n",
    "\n",
    "mse_best_ridge = mean_squared_error(test_y, predictions_best_ridge)\n",
    "mae_best_ridge = mean_absolute_error(test_y, predictions_best_ridge)\n",
    "r2_best_ridge = r2_score(test_y, predictions_best_ridge)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_best_ridge}, Mean Absolute Error: {mae_best_ridge}, R2 Score: {r2_best_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780e070",
   "metadata": {},
   "source": [
    "# XGBoost Linear Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d5bcc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression\n",
      "Train:\n",
      "Mean Squared Error: 108516.89344272856, Mean Absolute Error: 51.47972445958654, R2 Score: 0.9384480986302227\n",
      "Test:\n",
      "Mean Squared Error: 95556.38385120589, Mean Absolute Error: 52.06407352788963, R2 Score: 0.947195127269571\n",
      "\n",
      "Model: Ridge\n",
      "Train:\n",
      "Mean Squared Error: 108579.84410303934, Mean Absolute Error: 50.815370375577636, R2 Score: 0.938416689353522\n",
      "Test:\n",
      "Mean Squared Error: 94677.04082883865, Mean Absolute Error: 51.08124179038601, R2 Score: 0.9478272208966402\n",
      "\n",
      "Model: Lasso\n",
      "Train:\n",
      "Mean Squared Error: 109886.87263619372, Mean Absolute Error: 47.375098502699494, R2 Score: 0.9187974022642801\n",
      "Test:\n",
      "Mean Squared Error: 92647.37427532733, Mean Absolute Error: 45.63315575801159, R2 Score: 0.9283937215441126\n",
      "\n",
      "Model: ElasticNet\n",
      "Train:\n",
      "Mean Squared Error: 124136.38616147464, Mean Absolute Error: 46.36644964378157, R2 Score: 0.9199475304544128\n",
      "Test:\n",
      "Mean Squared Error: 106389.18800733976, Mean Absolute Error: 41.39918619411195, R2 Score: 0.9301377577020761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "ridge_model = Ridge()\n",
    "lasso_model = Lasso()\n",
    "en_model = ElasticNet()\n",
    "\n",
    "linear_models = [linear_model, ridge_model, lasso_model, en_model]\n",
    "\n",
    "xgb = joblib.load('xgb.joblib')\n",
    "\n",
    "xgb_Y = xgb.predict(train_X)\n",
    "xgb_Y_test = xgb.predict(test_X)\n",
    "\n",
    "for model in linear_models:\n",
    "\n",
    "    model.fit(train_X, xgb_Y)\n",
    "    train_predictions = model.predict(train_X)\n",
    "    test_predictions = model.predict(test_X)\n",
    "\n",
    "    train_mse = mean_squared_error(xgb_Y, train_predictions)\n",
    "    train_mae = mean_absolute_error(xgb_Y, train_predictions)\n",
    "    train_r2 = r2_score(xgb_Y, train_predictions)\n",
    "\n",
    "    test_mse = mean_squared_error(xgb_Y_test, test_predictions)\n",
    "    test_mae = mean_absolute_error(xgb_Y_test, test_predictions)\n",
    "    test_r2 = r2_score(xgb_Y_test, test_predictions)\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\\nTrain:\\nMean Squared Error: {train_mse}, Mean Absolute Error: {train_mae}, R2 Score: {train_r2}\")\n",
    "    print(f\"Test:\\nMean Squared Error: {test_mse}, Mean Absolute Error: {test_mae}, R2 Score: {test_r2}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d1120dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_ridge_aprox.joblib']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ridge_model, 'xgb_ridge_aprox.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93a28523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_linreg_aprox.joblib']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(linear_model, 'xgb_linreg_aprox.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fec2ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 74026.29111514364, Mean Absolute Error: 53.16997193188106, R2 Score: 0.9306869567365544\n"
     ]
    }
   ],
   "source": [
    "p=ridge_model.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(test_y, p)\n",
    "mae = mean_absolute_error(test_y, p)\n",
    "r2 = r2_score(test_y, p)\n",
    "print(f\"Mean Squared Error: {mse}, Mean Absolute Error: {mae}, R2 Score: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
