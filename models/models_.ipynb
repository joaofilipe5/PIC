{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7efcf42",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5d52c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94082afe",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37436d88",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "13d0cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac5e47",
   "metadata": {},
   "source": [
    "Sorting by year (avoids misshifting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5d678255",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by='Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2ab11",
   "metadata": {},
   "source": [
    "Define target columns for model and add new column for previous year pending cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d5dc9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_specific = [column for column in data.columns if 'CC' in column and column != 'CC_all']\n",
    "target_all = 'CC_all'\n",
    "for pc_column in [col for col in data.columns if 'PC' in col]:\n",
    "    data[pc_column + '_prev_year'] = data.groupby(['Court', 'Municipality', 'Bench'])[pc_column].shift(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f0d0f",
   "metadata": {},
   "source": [
    "Drop Incoming Cases and Pending Cases columns (unknown when predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5d4e674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[col for col in data.columns if 'PC_all' in col or 'IC' in col or ('PC' in col and '_prev_year' not in col)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad95fa2",
   "metadata": {},
   "source": [
    "Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9d2baf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Court', 'Municipality', 'Bench']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb8e78",
   "metadata": {},
   "source": [
    "Drop 'Informatic People' variable - only 1 entry in 2017, with value 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "67a436a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Informatic People'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6d1c1",
   "metadata": {},
   "source": [
    "Drop Justice Officials - sum of 6 prior columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d92b80bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Justice Officials'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[280], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mJustice Officials\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Justice Officials'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data = data.drop(columns=['Justice Officials'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "66e3bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0, how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ace0f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d1175e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2023 = data[data['Year'] == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9f2feee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a8869",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "26eda386",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data.drop(columns=target_specific+[target_all]), data[target_specific], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b7acc",
   "metadata": {},
   "source": [
    "Train test split for ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "720d432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ensemble = train_X.sample(frac=0.75, random_state=42)\n",
    "train_y_ensemble = train_y.loc[train_X_ensemble.index]\n",
    "validation_X_ensemble = train_X.drop(train_X_ensemble.index)\n",
    "validation_y_ensemble = train_y.loc[validation_X_ensemble.index]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_X_lr = train_X_ensemble.sample(frac=0.33, random_state=42)\n",
    "train_y_lr = train_y_ensemble.loc[train_X_lr.index]\n",
    "\n",
    "train_X_rf = train_X_ensemble.drop(train_X_lr.index).sample(frac=0.5, random_state=42)\n",
    "train_y_rf = train_y_ensemble.loc[train_X_rf.index]\n",
    "\n",
    "train_X_xgb = train_X_ensemble.drop(train_X_lr.index).drop(train_X_rf.index)\n",
    "train_y_xgb = train_y_ensemble.loc[train_X_xgb.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e520f198",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "7cfecf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Court\n",
      "Municipality\n",
      "Bench\n",
      "Judges\n",
      "Justice Secretary\n",
      "Law Clerck\n",
      "Auxiliar Clerck\n",
      "Administrative/Technical People\n",
      "Operational/Auxiliar People\n",
      "PC_Civil_prev_year\n",
      "PC_Criminal_prev_year\n",
      "PC_labor_prev_year\n",
      "PC_criminal_labor_prev_year\n",
      "PC_tutelar_prev_year\n",
      "PC_militar_prev_year\n"
     ]
    }
   ],
   "source": [
    "print('Court')\n",
    "print('Municipality')\n",
    "print('Bench')\n",
    "for col in train_X.columns:\n",
    "    print(col) if 'Court' not in col and 'Municipality' not in col and 'Bench' not in col else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed25cac0",
   "metadata": {},
   "source": [
    "# First models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80181b41",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ee0d6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 97540.49385853451, Mean Absolute Error: 80.13553578991953, R2 Score: 0.9029555676722651\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_X, train_y)\n",
    "\n",
    "predictions_lr = lr.predict(test_X)\n",
    "predictions_lr = predictions_lr.round(0)\n",
    "\n",
    "\n",
    "mse_lr = mean_squared_error(test_y, predictions_lr)\n",
    "mae_lr = mean_absolute_error(test_y, predictions_lr)\n",
    "r2_lr = r2_score(test_y, predictions_lr)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_lr}, Mean Absolute Error: {mae_lr}, R2 Score: {r2_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f8e87ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_regression.joblib']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, 'linear_regression.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a031d19",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fb5c2faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 167641.49216433713, Mean Absolute Error: 49.15798390512495, R2 Score: 0.8670237316097328\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "dt.fit(train_X, train_y)\n",
    "\n",
    "predictions_dt = dt.predict(test_X)\n",
    "predictions_dt = predictions_dt.round(0)\n",
    "\n",
    "mse_dt = mean_squared_error(test_y, predictions_dt)\n",
    "mae_dt = mean_absolute_error(test_y, predictions_dt)\n",
    "r2_dt = r2_score(test_y, predictions_dt)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_dt}, Mean Absolute Error: {mae_dt}, R2 Score: {r2_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e14486a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "239\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dt.max_features_)\n",
    "print(dt.n_features_in_)\n",
    "print(dt.n_outputs_)\n",
    "dt.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c27f4",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "cfbb78e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 107863.5390625, Mean Absolute Error: 38.9576416015625, R2 Score: 0.917310893535614\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "xgb.fit(train_X, train_y)\n",
    "\n",
    "predictions_xgb = xgb.predict(test_X)\n",
    "predictions_xgb = predictions_xgb.round(0)\n",
    "\n",
    "mse_xgb = mean_squared_error(test_y, predictions_xgb)\n",
    "mae_xgb = mean_absolute_error(test_y, predictions_xgb)\n",
    "r2_xgb = r2_score(test_y, predictions_xgb)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_xgb}, Mean Absolute Error: {mae_xgb}, R2 Score: {r2_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "95317fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb.joblib']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb, 'xgb.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63500b9f",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4ecba53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 93863.32274459973, Mean Absolute Error: 37.999576450656505, R2 Score: 0.9058898242860973\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf.fit(train_X, train_y)\n",
    "\n",
    "predictions_rf = rf.predict(test_X)\n",
    "predictions_rf = predictions_rf.round(0)\n",
    "\n",
    "mse_rf = mean_squared_error(test_y, predictions_rf)\n",
    "mae_rf = mean_absolute_error(test_y, predictions_rf)\n",
    "r2_rf = r2_score(test_y, predictions_rf)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_rf}, Mean Absolute Error: {mae_rf}, R2 Score: {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bed1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rf.n_features_in_)\n",
    "print(rf.n_outputs_)\n",
    "len(rf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1db3f242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "maxd= 0\n",
    "for t in rf.estimators_:\n",
    "    if t.tree_.max_depth > maxd:\n",
    "        maxd = t.tree_.max_depth\n",
    "print(maxd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557d9a8",
   "metadata": {},
   "source": [
    "Check correlations between the errors of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7c35ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_lr = test_y.values - predictions_lr\n",
    "residual_xgb = test_y.values - predictions_xgb\n",
    "residual_rf = test_y.values - predictions_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4860ba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix for CC_Civil:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.427367       0.541378\n",
      "XGBoost                     0.427367  1.000000       0.907137\n",
      "Random Forest               0.541378  0.907137       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_Criminal:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.072928       0.466520\n",
      "XGBoost                     0.072928  1.000000       0.500934\n",
      "Random Forest               0.466520  0.500934       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_labor:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.754126       0.833792\n",
      "XGBoost                     0.754126  1.000000       0.879763\n",
      "Random Forest               0.833792  0.879763       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_criminal_labor:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.680976       0.746940\n",
      "XGBoost                     0.680976  1.000000       0.934962\n",
      "Random Forest               0.746940  0.934962       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_tutelar:\n",
      "                   Linear Regression   XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.484556       0.664514\n",
      "XGBoost                     0.484556  1.000000       0.834563\n",
      "Random Forest               0.664514  0.834563       1.000000\n",
      "\n",
      "\n",
      "Correlation matrix for CC_militar:\n",
      "                   Linear Regression  XGBoost  Random Forest\n",
      "Linear Regression           1.000000  0.56997       0.206666\n",
      "XGBoost                     0.569970  1.00000      -0.067070\n",
      "Random Forest               0.206666 -0.06707       1.000000\n",
      "\n",
      "\n",
      "Average Correlations Across Targets:\n",
      "('Linear Regression', 'XGBoost'): 0.498\n",
      "('Linear Regression', 'Random Forest'): 0.577\n",
      "('XGBoost', 'Random Forest'): 0.665\n"
     ]
    }
   ],
   "source": [
    "correlation_results = {}\n",
    "\n",
    "for i, target in enumerate(target_specific):\n",
    "    # Build a DataFrame for the residuals for this target\n",
    "    df_target = pd.DataFrame({\n",
    "        'Linear Regression': residual_lr[:, i],\n",
    "        'XGBoost': residual_xgb[:, i],\n",
    "        'Random Forest': residual_rf[:, i]\n",
    "    })\n",
    "\n",
    "    correlation_results[target] = df_target.corr()\n",
    "\n",
    "for target, corr_matrix in correlation_results.items():\n",
    "    print(f\"Correlation matrix for {target}:\")\n",
    "    print(corr_matrix)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "model_pairs = [\n",
    "    ('Linear Regression', 'XGBoost'),\n",
    "    ('Linear Regression', 'Random Forest'),\n",
    "    ('XGBoost', 'Random Forest')\n",
    "]\n",
    "\n",
    "avg_correlations = {pair: [] for pair in model_pairs}\n",
    "\n",
    "for i, target in enumerate(target_specific):\n",
    "    df_target = pd.DataFrame({\n",
    "        'Linear Regression': residual_lr[:, i],\n",
    "        'XGBoost': residual_xgb[:, i],\n",
    "        'Random Forest': residual_rf[:, i]\n",
    "    })\n",
    "    corr = df_target.corr()\n",
    "    for pair in model_pairs:\n",
    "        avg_correlations[pair].append(corr.loc[pair[0], pair[1]])\n",
    "\n",
    "\n",
    "print(\"Average Correlations Across Targets:\")\n",
    "for pair, values in avg_correlations.items():\n",
    "    avg_corr = np.mean(values)\n",
    "    print(f\"{pair}: {avg_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3b060",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3dc6f6",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20070b9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Perform Grid Search with Cross-Validation\u001b[39;00m\n\u001b[0;32m      8\u001b[0m grid_search_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mgrid_search_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Get the best number of estimators\u001b[39;00m\n\u001b[0;32m     12\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m grid_search_rf\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {'n_estimators': range(10,201,10), 'max_depth': range(1, 21)}\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_rf.fit(train_X, train_y)\n",
    "\n",
    "# Get the best number of estimators\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_n_estimators = grid_search_rf.best_params_['n_estimators']\n",
    "best_max_depth = grid_search_rf.best_params_['max_depth']\n",
    "print(f\"Best number of estimators: {best_n_estimators}\")\n",
    "print(f\"Best max depth: {best_max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af0bc46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 101820.5675597646, Mean Absolute Error: 39.17148055688731, R2 Score: 0.9073725601697918\n"
     ]
    }
   ],
   "source": [
    "best_rf.predict(test_X)\n",
    "\n",
    "mse_brf = mean_squared_error(test_y, best_rf.predict(test_X))\n",
    "mae_brf = mean_absolute_error(test_y, best_rf.predict(test_X))\n",
    "r2_brf = r2_score(test_y, best_rf.predict(test_X))\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_brf}, Mean Absolute Error: {mae_brf}, R2 Score: {r2_brf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00554d09",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c05a478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    'n_estimators': range(10, 101, 5),\n",
    "    'max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_xgb.fit(train_X, train_y)\n",
    "\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "grid_search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eea690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 107589.7109375, Mean Absolute Error: 46.88821029663086, R2 Score: -0.8458577990531921\n"
     ]
    }
   ],
   "source": [
    "best_xgb.predict(test_X)\n",
    "\n",
    "mse_bxgb = mean_squared_error(test_y, best_xgb.predict(test_X))\n",
    "mae_bxgb = mean_absolute_error(test_y, best_xgb.predict(test_X))\n",
    "r2_bxgb = r2_score(test_y, best_xgb.predict(test_X))\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_bxgb}, Mean Absolute Error: {mae_bxgb}, R2 Score: {r2_bxgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61251e",
   "metadata": {},
   "source": [
    "Same takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65a0f1",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc6cc1",
   "metadata": {},
   "source": [
    "Weighted Average Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3db38ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_mse_target(weights, predictions_target, y_true_target):\n",
    "    \"\"\"\n",
    "    Compute MSE for a single target variable.\n",
    "    \"\"\"\n",
    "    # Weighted prediction for one target: dot product of weights and model predictions.\n",
    "    ensemble_pred = np.dot(weights, predictions_target)  # predictions_target shape: (n_models, n_samples)\n",
    "    mse = np.mean((y_true_target - ensemble_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "def ensemble_r2_target(weights, predictions_target, y_true_target):\n",
    "    \"\"\"\n",
    "    Compute R2 for a single target variable.\n",
    "    \"\"\"\n",
    "    # Weighted prediction for one target: dot product of weights and model predictions.\n",
    "    ensemble_pred = np.dot(weights, predictions_target)  # predictions_target shape: (n_models, n_samples)\n",
    "    return -r2_score(y_true_target, ensemble_pred)\n",
    "\n",
    "def ensemble_mae_target(weights, predictions_target, y_true_target):\n",
    "    \"\"\"\n",
    "    Compute MAE for a single target variable.\n",
    "    \"\"\"\n",
    "    # Weighted prediction for one target: dot product of weights and model predictions.\n",
    "    ensemble_pred = np.dot(weights, predictions_target)  # predictions_target shape: (n_models, n_samples)\n",
    "    mae = np.mean(np.abs(y_true_target - ensemble_pred))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d2dd8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Mean Squared Error: 158803.66221374043, Mean Absolute Error: 94.55322307039864, R2 Score: 0.8457085064546043\n",
      "Random Forest:\n",
      "Mean Squared Error: 159223.95419847328, Mean Absolute Error: 49.901611535199315, R2 Score: 0.8128927884003371\n",
      "XGBoost:\n",
      "Mean Squared Error: 154619.015625, Mean Absolute Error: 45.62234878540039, R2 Score: 0.7272852063179016\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression:')\n",
    "lrs = []\n",
    "for train_idx, val_idx in kf.split(train_X_lr):\n",
    "    X_train, X_val = train_X_lr.iloc[train_idx], train_X_lr.iloc[val_idx]\n",
    "    y_train = train_y_lr.iloc[train_idx]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)  # trains on 704 samples\n",
    "    lrs.append(model)\n",
    "\n",
    "predictions_lre = np.mean([lr.predict(validation_X_ensemble) for lr in lrs], axis=0)\n",
    "predictions_lre_rounded = predictions_lre.round(0)\n",
    "mse_lre = mean_squared_error(validation_y_ensemble, predictions_lre_rounded)\n",
    "mae_lre = mean_absolute_error(validation_y_ensemble, predictions_lre_rounded)\n",
    "r2_lre = r2_score(validation_y_ensemble, predictions_lre_rounded)\n",
    "print(f\"Mean Squared Error: {mse_lre}, Mean Absolute Error: {mae_lre}, R2 Score: {r2_lre}\")\n",
    "\n",
    "print('Random Forest:')\n",
    "rfs = []\n",
    "for train_idx, val_idx in kf.split(train_X_rf):\n",
    "    X_train, X_val = train_X_rf.iloc[train_idx], train_X_rf.iloc[val_idx]\n",
    "    y_train = train_y_rf.iloc[train_idx]\n",
    "\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)  # trains on 704 samples\n",
    "    rfs.append(model)\n",
    "\n",
    "predictions_rfe = np.mean([rf.predict(validation_X_ensemble) for rf in rfs], axis=0)\n",
    "predictions_rfe_rounded = predictions_rfe.round(0)\n",
    "mse_rfe = mean_squared_error(validation_y_ensemble, predictions_rfe_rounded)\n",
    "mae_rfe = mean_absolute_error(validation_y_ensemble, predictions_rfe_rounded)\n",
    "r2_rfe = r2_score(validation_y_ensemble, predictions_rfe_rounded)\n",
    "print(f\"Mean Squared Error: {mse_rfe}, Mean Absolute Error: {mae_rfe}, R2 Score: {r2_rfe}\")\n",
    "\n",
    "print('XGBoost:')\n",
    "xgbs = []\n",
    "for train_idx, val_idx in kf.split(train_X_xgb):\n",
    "    X_train, X_val = train_X_xgb.iloc[train_idx], train_X_xgb.iloc[val_idx]\n",
    "    y_train = train_y_xgb.iloc[train_idx]\n",
    "\n",
    "    model = XGBRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)  # trains on 704 samples\n",
    "    xgbs.append(model)\n",
    "\n",
    "predictions_xgbe = np.mean([xgb.predict(validation_X_ensemble) for xgb in xgbs], axis=0)\n",
    "predictions_xgbe_rounded = predictions_xgbe.round(0)\n",
    "mse_xgbe = mean_squared_error(validation_y_ensemble, predictions_xgbe_rounded)\n",
    "mae_xgbe = mean_absolute_error(validation_y_ensemble, predictions_xgbe_rounded)\n",
    "r2_xgbe = r2_score(validation_y_ensemble, predictions_xgbe_rounded)\n",
    "print(f\"Mean Squared Error: {mse_xgbe}, Mean Absolute Error: {mae_xgbe}, R2 Score: {r2_xgbe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e462bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.array([np.mean([lr.predict(test_X) for lr in lrs], axis=0),\n",
    "                             np.mean([xgb.predict(test_X) for xgb in xgbs], axis=0), \n",
    "                             np.mean([rf.predict(test_X) for rf in rfs], axis=0)])\n",
    "test_predictions_rounded = test_predictions.round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d36e4",
   "metadata": {},
   "source": [
    "MSE as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cca20039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights and Corresponding Models per Target:\n",
      "CC_Civil:\n",
      "  Linear Regression: 0.4356\n",
      "  XGBoost: 0.2087\n",
      "  Random Forest: 0.3557\n",
      "CC_Criminal:\n",
      "  Linear Regression: 0.2618\n",
      "  XGBoost: 0.7358\n",
      "  Random Forest: 0.0024\n",
      "CC_labor:\n",
      "  Linear Regression: 0.3263\n",
      "  XGBoost: 0.5551\n",
      "  Random Forest: 0.1185\n",
      "CC_criminal_labor:\n",
      "  Linear Regression: 0.3514\n",
      "  XGBoost: 0.4139\n",
      "  Random Forest: 0.2348\n",
      "CC_tutelar:\n",
      "  Linear Regression: 0.0216\n",
      "  XGBoost: 0.2394\n",
      "  Random Forest: 0.7390\n",
      "CC_militar:\n",
      "  Linear Regression: 1.0000\n",
      "  XGBoost: 0.0000\n",
      "  Random Forest: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "n_models = 3  # Number of models\n",
    "n_targets = 6  # Number of targets\n",
    "n_samples = validation_y_ensemble.shape[0]  # Number of samples in the test set\n",
    "\n",
    "predictions = np.array([predictions_lre, predictions_xgbe, predictions_rfe])\n",
    "y_val = validation_y_ensemble.values\n",
    "\n",
    "# Assume y_val and predictions are defined as before.\n",
    "optimal_weights_per_target = np.zeros((n_models, n_targets)) # 4 models, 6 targets\n",
    "\n",
    "\n",
    "for i in range(n_targets):  # Assuming 6 targets\n",
    "    # Extract predictions for target i: shape becomes (n_models, n_samples)\n",
    "    predictions_i = predictions[:, :, i]\n",
    "    y_true_i = y_val[:, i]\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1)] * n_models\n",
    "    initial_weights = np.full(n_models, 1.0 / n_models)\n",
    "    \n",
    "    result = minimize(ensemble_mse_target, initial_weights, args=(predictions_i, y_true_i),\n",
    "                      bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    optimal_weights_per_target[:, i] = result.x\n",
    "\n",
    "model_names = ['Linear Regression', 'XGBoost', 'Random Forest']\n",
    "print(\"Optimal Weights and Corresponding Models per Target:\")\n",
    "for i, target in enumerate(target_specific):\n",
    "    print(f\"{target}:\")\n",
    "    for weight, model in zip(optimal_weights_per_target[:, i], model_names):\n",
    "        print(f\"  {model}: {weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fd1a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ensemble predictions for each target using the corresponding weights\n",
    "n_test_samples = test_predictions.shape[1]  # Number of samples in the test set\n",
    "ensemble_pred_separate = np.zeros((n_test_samples, n_targets))\n",
    "for i in range(n_targets):\n",
    "    ensemble_pred_separate[:, i] = np.dot(optimal_weights_per_target[:, i], test_predictions[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b610348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 87949.09783989836, Mean Absolute Error: 54.04997882253283, R2 Score: 0.9045132708098724\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred_separate = ensemble_pred_separate.round(0)\n",
    "ensemble_mse = mean_squared_error(test_y, ensemble_pred_separate)\n",
    "ensemble_mae = mean_absolute_error(test_y, ensemble_pred_separate)\n",
    "ensemble_r2 = r2_score(test_y, ensemble_pred_separate)\n",
    "\n",
    "print(f\"Mean Squared Error: {ensemble_mse}, Mean Absolute Error: {ensemble_mae}, R2 Score: {ensemble_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e8057",
   "metadata": {},
   "source": [
    "R^2 as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58d01a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights and Corresponding Models per Target:\n",
      "CC_Civil:\n",
      "  Linear Regression: 0.4367\n",
      "  XGBoost: 0.2072\n",
      "  Random Forest: 0.3561\n",
      "CC_Criminal:\n",
      "  Linear Regression: 0.2618\n",
      "  XGBoost: 0.7359\n",
      "  Random Forest: 0.0023\n",
      "CC_labor:\n",
      "  Linear Regression: 0.3263\n",
      "  XGBoost: 0.5551\n",
      "  Random Forest: 0.1185\n",
      "CC_criminal_labor:\n",
      "  Linear Regression: 0.3514\n",
      "  XGBoost: 0.4141\n",
      "  Random Forest: 0.2345\n",
      "CC_tutelar:\n",
      "  Linear Regression: 0.0190\n",
      "  XGBoost: 0.2406\n",
      "  Random Forest: 0.7404\n",
      "CC_militar:\n",
      "  Linear Regression: 1.0000\n",
      "  XGBoost: 0.0000\n",
      "  Random Forest: 0.0000\n"
     ]
    }
   ],
   "source": [
    "n_models = 3  # Number of models\n",
    "n_targets = 6  # Number of targets\n",
    "n_samples = validation_y_ensemble.shape[0]  # Number of samples in the validation set\n",
    "\n",
    "predictions = np.array([predictions_lre, predictions_xgbe, predictions_rfe])\n",
    "y_val = validation_y_ensemble.values\n",
    "\n",
    "# Assume y_val and predictions are defined as before.\n",
    "optimal_weights_per_target_r2 = np.zeros((n_models, n_targets)) # 3 models, 6 targets\n",
    "\n",
    "\n",
    "for i in range(n_targets):  # Assuming 6 targets\n",
    "    # Extract predictions for target i: shape becomes (n_models, n_samples)\n",
    "    predictions_i = predictions[:, :, i]\n",
    "    y_true_i = y_val[:, i]\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1)] * n_models\n",
    "    initial_weights = np.full(n_models, 1.0 / n_models)\n",
    "    \n",
    "    result = minimize(ensemble_r2_target, initial_weights, args=(predictions_i, y_true_i),\n",
    "                      bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    optimal_weights_per_target_r2[:, i] = result.x\n",
    "\n",
    "model_names = ['Linear Regression', 'XGBoost', 'Random Forest']\n",
    "print(\"Optimal Weights and Corresponding Models per Target:\")\n",
    "for i, target in enumerate(target_specific):\n",
    "    print(f\"{target}:\")\n",
    "    for weight, model in zip(optimal_weights_per_target_r2[:, i], model_names):\n",
    "        print(f\"  {model}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e685b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ensemble predictions for each target using the corresponding weights\n",
    "n_test_samples = test_predictions.shape[1]  # Number of samples in the test set\n",
    "ensemble_pred_separate_r2 = np.zeros((n_test_samples, n_targets))\n",
    "for i in range(n_targets):\n",
    "    ensemble_pred_separate_r2[:, i] = np.dot(optimal_weights_per_target_r2[:, i], test_predictions[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1088ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 88011.83248623465, Mean Absolute Error: 54.090427784836926, R2 Score: 0.9045047979825599\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred_separate_r2 = ensemble_pred_separate_r2.round(0)\n",
    "ensemble_mse = mean_squared_error(test_y, ensemble_pred_separate_r2)\n",
    "ensemble_mae = mean_absolute_error(test_y, ensemble_pred_separate_r2)\n",
    "ensemble_r2 = r2_score(test_y, ensemble_pred_separate_r2)\n",
    "\n",
    "print(f\"Mean Squared Error: {ensemble_mse}, Mean Absolute Error: {ensemble_mae}, R2 Score: {ensemble_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929a23b",
   "metadata": {},
   "source": [
    "MAE as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7924a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights and Corresponding Models per Target:\n",
      "CC_Civil:\n",
      "  Linear Regression: 0.0134\n",
      "  XGBoost: 0.6114\n",
      "  Random Forest: 0.3752\n",
      "CC_Criminal:\n",
      "  Linear Regression: 0.0078\n",
      "  XGBoost: 0.9922\n",
      "  Random Forest: 0.0000\n",
      "CC_labor:\n",
      "  Linear Regression: 0.0000\n",
      "  XGBoost: 0.8181\n",
      "  Random Forest: 0.1819\n",
      "CC_criminal_labor:\n",
      "  Linear Regression: 0.0000\n",
      "  XGBoost: 0.5432\n",
      "  Random Forest: 0.4568\n",
      "CC_tutelar:\n",
      "  Linear Regression: 0.0001\n",
      "  XGBoost: 0.4704\n",
      "  Random Forest: 0.5295\n",
      "CC_militar:\n",
      "  Linear Regression: 0.0000\n",
      "  XGBoost: 0.3615\n",
      "  Random Forest: 0.6385\n"
     ]
    }
   ],
   "source": [
    "n_models = 3  # Number of models\n",
    "n_targets = 6  # Number of targets\n",
    "n_samples = validation_y_ensemble.shape[0]  # Number of samples in the validation set\n",
    "\n",
    "predictions = np.array([predictions_lre, predictions_xgbe, predictions_rfe])\n",
    "y_val = validation_y_ensemble.values\n",
    "\n",
    "# Assume y_val and predictions are defined as before.\n",
    "optimal_weights_per_target_mae = np.zeros((n_models, n_targets)) # 3 models, 6 targets\n",
    "\n",
    "\n",
    "for i in range(n_targets):  # Assuming 6 targets\n",
    "    # Extract predictions for target i: shape becomes (n_models, n_samples)\n",
    "    predictions_i = predictions[:, :, i]\n",
    "    y_true_i = y_val[:, i]\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1)] * n_models\n",
    "    initial_weights = np.full(n_models, 1.0 / n_models)\n",
    "    \n",
    "    result = minimize(ensemble_mae_target, initial_weights, args=(predictions_i, y_true_i),\n",
    "                      bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    optimal_weights_per_target_mae[:, i] = result.x\n",
    "\n",
    "model_names = ['Linear Regression', 'XGBoost', 'Random Forest']\n",
    "print(\"Optimal Weights and Corresponding Models per Target:\")\n",
    "for i, target in enumerate(target_specific):\n",
    "    print(f\"{target}:\")\n",
    "    for weight, model in zip(optimal_weights_per_target_mae[:, i], model_names):\n",
    "        print(f\"  {model}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d7c3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ensemble predictions for each target using the corresponding weights\n",
    "n_test_samples = test_predictions.shape[1]  # Number of samples in the test set\n",
    "ensemble_pred_separate_mae = np.zeros((n_test_samples, n_targets))\n",
    "for i in range(n_targets):\n",
    "    ensemble_pred_separate_mae[:, i] = np.dot(optimal_weights_per_target_mae[:, i], test_predictions[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ae92b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 85668.30029648455, Mean Absolute Error: 40.59635747564591, R2 Score: 0.8112829814794457\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred_separate_mae = ensemble_pred_separate_mae.round(0)\n",
    "ensemble_mse = mean_squared_error(test_y, ensemble_pred_separate_mae)\n",
    "ensemble_mae = mean_absolute_error(test_y, ensemble_pred_separate_mae)\n",
    "ensemble_r2 = r2_score(test_y, ensemble_pred_separate_mae)\n",
    "\n",
    "print(f\"Mean Squared Error: {ensemble_mse}, Mean Absolute Error: {ensemble_mae}, R2 Score: {ensemble_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e96929",
   "metadata": {},
   "source": [
    "Meta-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712119f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X = np.hstack([predictions_lre, predictions_xgbe, predictions_rfe])\n",
    "\n",
    "meta_models = []\n",
    "for i in range(6):\n",
    "    y_val_i = y_val[:, i]\n",
    "    meta_model = Ridge()\n",
    "    meta_model.fit(meta_X, y_val_i)\n",
    "    meta_models.append(meta_model)\n",
    "\n",
    "# To predict on the test set:\n",
    "meta_X_test = np.hstack([np.mean([lr.predict(test_X) for lr in lrs], axis=0),\n",
    "                             np.mean([xgb.predict(test_X) for xgb in xgbs], axis=0), \n",
    "                             np.mean([rf.predict(test_X) for rf in rfs], axis=0)]\n",
    "                             )\n",
    "\n",
    "y_pred_meta_ensemble = np.column_stack([\n",
    "    meta_model.predict(meta_X_test) for meta_model in meta_models\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c49b2163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 104715.5483259255, Mean Absolute Error: 54.82581879882152, R2 Score: 0.910546016900815\n"
     ]
    }
   ],
   "source": [
    "meta_mse = mean_squared_error(test_y, y_pred_meta_ensemble)\n",
    "meta_mae = mean_absolute_error(test_y, y_pred_meta_ensemble)\n",
    "meta_r2 = r2_score(test_y, y_pred_meta_ensemble)\n",
    "\n",
    "print(f\"Mean Squared Error: {meta_mse}, Mean Absolute Error: {meta_mae}, R2 Score: {meta_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ee3d135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 116259.46293943243, Mean Absolute Error: 39.79500211774671, R2 Score: 0.9051820007427479\n",
      "Mean Squared Error: 103286.13002964847, Mean Absolute Error: 38.64464210080474, R2 Score: 0.9106146356425548\n",
      "Mean Squared Error: 112395.8958068615, Mean Absolute Error: 39.664548919949176, R2 Score: 0.9097691849497639\n",
      "Mean Squared Error: 114282.16539601861, Mean Absolute Error: 39.40724269377383, R2 Score: 0.9069180521948127\n",
      "Mean Squared Error: 105342.02117746715, Mean Absolute Error: 38.56077933079204, R2 Score: 0.9101732744556772\n",
      "Mean Squared Error: 106317.28759000421, Mean Absolute Error: 39.302414231257934, R2 Score: 0.9036262974177296\n",
      "Mean Squared Error: 100831.59085133417, Mean Absolute Error: 38.49047013977129, R2 Score: 0.9070415002184289\n",
      "Mean Squared Error: 104960.95235069886, Mean Absolute Error: 38.71812791190174, R2 Score: 0.9073506505111171\n",
      "Mean Squared Error: 109341.61562897079, Mean Absolute Error: 38.71685726387125, R2 Score: 0.9065626985094976\n",
      "Mean Squared Error: 102795.98623464633, Mean Absolute Error: 38.592757306226176, R2 Score: 0.9099199424504757\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "\n",
    "    rfr = RandomForestRegressor()\n",
    "    rfr.fit(train_X, train_y)\n",
    "    predictions_rfr = rfr.predict(test_X)\n",
    "    predictions_rfr = predictions_rfr.round(0)\n",
    "\n",
    "    mse_rfr = mean_squared_error(test_y, predictions_rfr)\n",
    "    mae_rfr = mean_absolute_error(test_y, predictions_rfr)\n",
    "    r2_rfr = r2_score(test_y, predictions_rfr)\n",
    "    print(f\"Mean Squared Error: {mse_rfr}, Mean Absolute Error: {mae_rfr}, R2 Score: {r2_rfr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72485f2d",
   "metadata": {},
   "source": [
    "# More Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb335053",
   "metadata": {},
   "source": [
    "Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "543f2f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 94231.47183396867, Mean Absolute Error: 75.95552731893265, R2 Score: 0.9054785299782121\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=8)\n",
    "ridge.fit(train_X, train_y)\n",
    "\n",
    "predictions_ridge = ridge.predict(test_X)\n",
    "predictions_ridge = predictions_ridge.round(0)\n",
    "\n",
    "\n",
    "mse_ridge = mean_squared_error(test_y, predictions_ridge)\n",
    "mae_ridge = mean_absolute_error(test_y, predictions_ridge)\n",
    "r2_ridge = r2_score(test_y, predictions_ridge)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_ridge}, Mean Absolute Error: {mae_ridge}, R2 Score: {r2_ridge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "409f5434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ridge.joblib']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ridge, 'ridge.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "be2e36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ridge.coef_, columns=train_X.columns).to_csv(\"ridge_coefs.csv\", index=False)\n",
    "pd.Series(ridge.intercept_).to_csv(\"ridge_intercepts.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "60f9f6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89385162e+02, -2.97464433e+02,  1.20372100e+01, ...,\n",
       "         2.98289088e+02, -1.60614330e+02,  4.68583439e+01],\n",
       "       [-3.40784881e+01,  2.26198418e+01,  1.99477461e+01, ...,\n",
       "        -8.35734087e+01,  1.62358233e+02,  6.04169081e+02],\n",
       "       [-2.78438230e+00,  3.17236100e+01, -3.89856732e-01, ...,\n",
       "        -6.54759794e-02,  1.47505061e+00, -1.66619056e+01],\n",
       "       [ 1.92120079e-01, -1.44775950e+00, -3.17047840e-02, ...,\n",
       "        -1.47216671e+00, -1.55756121e+00,  1.08979977e+00],\n",
       "       [-2.27253301e+00,  7.08521092e+00,  5.07877459e+00, ...,\n",
       "        -3.54720852e+01, -4.40637538e+01, -3.84596149e+01],\n",
       "       [ 7.67087582e-02,  6.36553210e-02, -3.17493237e-03, ...,\n",
       "        -7.81358164e-02,  8.59811868e-02, -2.03982483e-03]],\n",
       "      shape=(6, 242))"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "03b638ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.41712646e+02,  4.56875857e+01,  6.70050831e+00,  9.17605629e-01,\n",
       "        7.70984302e+00, -5.59680470e-02])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594e4e4",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "953bdeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 93685.08132147395, Mean Absolute Error: 73.14697162219397, R2 Score: 0.8544143562278622\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(train_X, train_y)\n",
    "\n",
    "predictions_lasso = lasso.predict(test_X)\n",
    "predictions_lasso = predictions_lasso.round(0)\n",
    "\n",
    "mse_lasso = mean_squared_error(test_y, predictions_lasso)\n",
    "mae_lasso = mean_absolute_error(test_y, predictions_lasso)\n",
    "r2_lasso = r2_score(test_y, predictions_lasso)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_lasso}, Mean Absolute Error: {mae_lasso}, R2 Score: {r2_lasso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d64b6",
   "metadata": {},
   "source": [
    "Elastic Net (mix of Ridge and Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "eafb544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 122019.84709868701, Mean Absolute Error: 83.82041507835663, R2 Score: 0.8358045255294889\n"
     ]
    }
   ],
   "source": [
    "en = ElasticNet()\n",
    "en.fit(train_X, train_y)\n",
    "\n",
    "predictions_en = en.predict(test_X)\n",
    "predictions_en = predictions_en.round(0)\n",
    "\n",
    "mse_en = mean_squared_error(test_y, predictions_en)\n",
    "mae_en = mean_absolute_error(test_y, predictions_en)\n",
    "r2_en = r2_score(test_y, predictions_en)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_en}, Mean Absolute Error: {mae_en}, R2 Score: {r2_en}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb195d",
   "metadata": {},
   "source": [
    "Ridge alpha optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "35c25a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 4.26\n",
      "Mean Squared Error: 94901.1721728081, Mean Absolute Error: 77.13617111393478, R2 Score: 0.9041275619455864\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for alpha\n",
    "param_grid_ridge = {'alpha': np.arange(0.01,15,0.01)}\n",
    "\n",
    "# Initialize the Ridge Regressor\n",
    "ridge = Ridge()\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search_ridge = GridSearchCV(estimator=ridge, param_grid=param_grid_ridge, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_ridge.fit(train_X, train_y)\n",
    "\n",
    "# Get the best alpha value\n",
    "best_ridge = grid_search_ridge.best_estimator_\n",
    "best_alpha = grid_search_ridge.best_params_['alpha']\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "predictions_best_ridge = best_ridge.predict(test_X)\n",
    "predictions_best_ridge = predictions_best_ridge.round(0)\n",
    "\n",
    "mse_best_ridge = mean_squared_error(test_y, predictions_best_ridge)\n",
    "mae_best_ridge = mean_absolute_error(test_y, predictions_best_ridge)\n",
    "r2_best_ridge = r2_score(test_y, predictions_best_ridge)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_best_ridge}, Mean Absolute Error: {mae_best_ridge}, R2 Score: {r2_best_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780e070",
   "metadata": {},
   "source": [
    "# XGBoost Linear Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "8d5bcc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression\n",
      "Train:\n",
      "Mean Squared Error: 119945.77867930969, Mean Absolute Error: 72.23028977147696, R2 Score: 0.9022102490610787\n",
      "Test:\n",
      "Mean Squared Error: 118015.67594799191, Mean Absolute Error: 80.43899426374468, R2 Score: 0.8903093049623904\n",
      "\n",
      "Model: Ridge\n",
      "Train:\n",
      "Mean Squared Error: 120083.68232234717, Mean Absolute Error: 71.60305409804589, R2 Score: 0.9020954381789403\n",
      "Test:\n",
      "Mean Squared Error: 116630.94609893647, Mean Absolute Error: 79.24005100863702, R2 Score: 0.8917296794679759\n",
      "\n",
      "Model: Lasso\n",
      "Train:\n",
      "Mean Squared Error: 122587.86492729346, Mean Absolute Error: 68.35998540297753, R2 Score: 0.8457356736540868\n",
      "Test:\n",
      "Mean Squared Error: 114688.32722428457, Mean Absolute Error: 73.16906338265315, R2 Score: 0.836541003218247\n",
      "\n",
      "Model: ElasticNet\n",
      "Train:\n",
      "Mean Squared Error: 167549.04122812528, Mean Absolute Error: 81.68477230201798, R2 Score: 0.8253331853125601\n",
      "Test:\n",
      "Mean Squared Error: 155665.02274419222, Mean Absolute Error: 82.21615368817407, R2 Score: 0.8109531655324683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "ridge_model = Ridge()\n",
    "lasso_model = Lasso()\n",
    "en_model = ElasticNet()\n",
    "\n",
    "linear_models = [linear_model, ridge_model, lasso_model, en_model]\n",
    "\n",
    "xgb = joblib.load('xgb.joblib')\n",
    "\n",
    "xgb_Y = xgb.predict(train_X)\n",
    "xgb_Y_test = xgb.predict(test_X)\n",
    "\n",
    "for model in linear_models:\n",
    "\n",
    "    model.fit(train_X, xgb_Y)\n",
    "    train_predictions = model.predict(train_X)\n",
    "    test_predictions = model.predict(test_X)\n",
    "\n",
    "    train_mse = mean_squared_error(xgb_Y, train_predictions)\n",
    "    train_mae = mean_absolute_error(xgb_Y, train_predictions)\n",
    "    train_r2 = r2_score(xgb_Y, train_predictions)\n",
    "\n",
    "    test_mse = mean_squared_error(xgb_Y_test, test_predictions)\n",
    "    test_mae = mean_absolute_error(xgb_Y_test, test_predictions)\n",
    "    test_r2 = r2_score(xgb_Y_test, test_predictions)\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\\nTrain:\\nMean Squared Error: {train_mse}, Mean Absolute Error: {train_mae}, R2 Score: {train_r2}\")\n",
    "    print(f\"Test:\\nMean Squared Error: {test_mse}, Mean Absolute Error: {test_mae}, R2 Score: {test_r2}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0d1120dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_ridge_aprox.joblib']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ridge_model, 'xgb_ridge_aprox.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "fec2ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 96443.81422490974, Mean Absolute Error: 79.09475014433956, R2 Score: 0.9031580346781141\n"
     ]
    }
   ],
   "source": [
    "p=ridge_model.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(test_y, p)\n",
    "mae = mean_absolute_error(test_y, p)\n",
    "r2 = r2_score(test_y, p)\n",
    "print(f\"Mean Squared Error: {mse}, Mean Absolute Error: {mae}, R2 Score: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
